version: "3.8"

services:
  fia-mcp-server:
    build:
      context: .
      dockerfile: Dockerfile
      platforms:
        - linux/amd64
    ports:
      - "8080:8080"
    environment:
      # Axcelerate Configuration
      - AXCELERATE_BASE_URL=${AXCELERATE_BASE_URL}
      - AXCELERATE_WSTOKEN=${AXCELERATE_WSTOKEN}
      - AXCELERATE_APITOKEN=${AXCELERATE_APITOKEN}
      # Azure OpenAI Configuration
      - AZURE_API_MODEL=${AZURE_API_MODEL}
      - AZURE_API_KEY=${AZURE_API_KEY}
      - AZURE_API_BASE=${AZURE_API_BASE}
      - AZURE_API_VERSION=${AZURE_API_VERSION}
      # OpenAI Configuration (for tracing)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Optional: Add a chatbot service for testing
  fia-chatbot:
    build:
      context: .
      dockerfile: Dockerfile
      platforms:
        - linux/amd64
    command: ["python", "-m", "src.test.chat"]
    environment:
      # Axcelerate Configuration
      - AXCELERATE_BASE_URL=${AXCELERATE_BASE_URL}
      - AXCELERATE_WSTOKEN=${AXCELERATE_WSTOKEN}
      - AXCELERATE_APITOKEN=${AXCELERATE_APITOKEN}
      # Azure OpenAI Configuration
      - AZURE_API_MODEL=${AZURE_API_MODEL}
      - AZURE_API_KEY=${AZURE_API_KEY}
      - AZURE_API_BASE=${AZURE_API_BASE}
      - AZURE_API_VERSION=${AZURE_API_VERSION}
      # OpenAI Configuration (for tracing)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - fia-mcp-server
    stdin_open: true
    tty: true
    profiles:
      - chatbot
